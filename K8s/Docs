## Intro to Kubernetes | Container Tools For Beginners | Orchestration Tools 

# Kubernetes: Understanding Communities and Software Development

 To understand Kubernetes, we first need to understand how software development works. Why do we need communities in software development?
 This is an important question, but before we dive into that, we have to understand Docker because it's a prerequisite for Kubernetes.
 Let me know in the chat if you have any questions or if you are not familiar with Docker or Kubernetes so I can adjust my teaching accordingly.
 
## What is Docker?

Docker is a container-based software technology used in DevOps. It's important to note that Docker is not exactly like Kubernetes.
They are different but related technologies.

## Why Do We Need Communities in Software Development?

Communities are used extensively in DevOps, especially in software development where profits need to be made.
Kubernetes is commonly used for deployment, which is where the software goes to the end-users, customers or testers.
The tester takes this code and tests it for various things such as requirement testing and build process testing. 
The aim is to ensure that the code goes to the user without any issues.


## The Importance of Community

In software development, communities are often used for a specific purpose. Communities help to ensure that the code goes out to the users without any issues.
They also help to create a sense of empathy and understanding within teams, which can go a long way in making the development process smoother and more efficient.

## Understanding Containerization and Docker

If you're looking to understand Docker, you need to understand containerization first.
Essentially, containerization solves compatibility issues that can arise from different devices being involved in software development and delivery.
The developer might test their code on one laptop with certain tools, while the tester uses another, and the production environment is on a server.
Making sure the code behaves the same way in all of these environments can be tedious and difficult.

This is where containers come in. Think of containers as virtual boxes that can hold all the necessary parts of an application in a single, deployable unit. Using containers instead of directly pushing the code to different devices makes the building and deployment process easier and more consistent. Docker is a containerization tool, which allows you to secure the application in a container and send it for deployment.

Containers act like virtual machines, but aren't exactly the same thing
Docker swarm is an open-source orchestrator tool that can help implement microservices architecture

Microservices are used to manage multiple isolated containers, and Docker is a tool for creating and managing those containers. However, to efficiently manage those containers, orchestration tools like Kubernetes are needed. Images can be used as blueprints to define how the container will be run, and Ubuntu can be specified as the operating system. Kubernetes is a tool for monitoring Docker and offers dashboards for managing different aspects of microservices. Companies might use Docker Swarm for prototype reasons, but Kubernetes is generally preferred for orchestration.

Feel free to ask any questions, and we'll be happy to answer them. Raj asked if the video could be uploaded to YouTube, and we'll upload the live session. We'll also offer recordings of live sessions from September and December, and we welcome any song recommendations. Thanks for being a subscriber since 2013!

Virtual machines are essentially machines that are virtual, as the name suggests. They do not interact with the current Windows system, so if, for example, Ubuntu is installed in a virtual machine, it will run separately and will not directly affect the system. If you are not ready to watch the video now, you can subscribe and come back later to check on your subscription feed to watch the live sessions, which will help you out.

Some questions were asked, such as which service is used in AWS, and it is usually EKS. Different parameter values in each environment can be resolved using environment variables. AWS has many different services being developed by different teams. Kubernetes is an open source container orchestration tool that manages multiple containers and environments, while Docker Swarm is used primarily for containerization.

Windows Server was used as an example of how to use Windows on a container to install different tools or software. Kubernetes is a robust tool that provides stability and reduces downtime, making it a better option than Docker when it comes to security. The software uses a microservices architecture and storage distribution or handling of secrets.

Storage distribution refers to the effect on the system's storage, and availability of volumes can quickly resolve issues. It is important not to store data in the system and to utilize volumes to share data between containers.


## Kubernetes Architecture Overview

Kubernetes is used to manage three services through a community designed and built infrastructure. 
The architecture is organized into pods, which contain multiple containers running simultaneously.
It is important to not store data within containers and instead direct it to external volumes. 
Kubernetes can manage the sharing of these volumes across containers. Kubernetes is also responsible for storage distribution, secret handling, 
healing, load balancing, and easy scaling. Replicas of features are automatically deployed in case of downtime or failure. 
Kubernetes also comes with easy installation and setup.

## Pods
Pods represent services
Containers within a pod are managed for efficiency purposes
Data should not be stored within containers (use external volumes instead)
Kubernetes manages sharing volumes among containers
Features/Services
Replicas automatically installed for easy recovery
Load balancing distributes requests coming in from outside the service
Easy scaling allows for increasing the number of servers

We are using two CPUs and 4GB memory for Kubernetes, as it needs at least two CPUs. We are using Ubuntu Server and accessing the servers through a client called Putty. We have two nodes within our cluster communities cluster, which allows for multiple pods on those servers.

To update our instance, we use the apt-get update command to get root access by using the su command. We use a private key to access the servers, but you can also use any bash terminal or PowerShell directly. If you use a public key, make sure you are using the correct key to access your private key.

To work with Docker, we need to install app transport https and curl packages, in addition to Docker itself. We also need to get a key that allows us to access the repository where Kubernetes is located. First, we get an "ok" and then install Kubernetes itself. We also need a signing key for Kubernetes.

Curl is used to get URLs, and we will have it in our system. We will not directly type in the key, but use the app transport to install it. After installing Docker using the command line, we will use the tool for Docker. Using a shell script is an easy method to copy-paste the commands you want to execute for running communities.

You can run communities on laptops with 4GB RAM, and the script will give you a good idea of how to run it. The following commands need to be executed to install and add the communities to the community repository:

apt-get install cube-admin cube-led and cube-ctl
apt-add-repository "deb http://apt.kubernetes.io/ kubernetes-xenial main"
apt-get install kubectl
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -
apt-get update
Once installed, check if Cube Admin is installed properly by typing "cube-admin version." Cube Admin is installed in the system using apt command, which is the package manager used for Ubuntu.

Creating and Joining Nodes in a Cluster
This session is focused on creating and joining nodes in a cluster. The first step is to copy the join token command, ensuring that both Communities and Docker are installed. Once the join command is pasted and entered, the node will join the cluster, and the command "kubectl get nodes" will display the joined nodes.

Kubernetes is generally used for deployment purposes, allowing for multiple pods to easily handle features such as load balancing and self-healing. The session was more theory-based, but a homework assignment is given to learn more about Communities and Docker. The next session will aim to create a cluster and launch an application within it to demonstrate Kubernetes.
